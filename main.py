import os.path

import pymysql
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
from javlibrary_crawler.spiders.works_spider import WorksSpider
from javlibrary_crawler.spiders.magnet_spider import MagnetSpider
from scrapy import signals
from scrapy.signalmanager import dispatcher
import dbop.mysql_op as mysql_op
from config.database_config import MYSQL_CONFIG, MYSQL_DBNAME
from preview_download import download_preview as pdown
from config import arguments


def main():
    # åˆ›å»ºä¸€ä¸ªCrawlerProcess
    process = CrawlerProcess(get_project_settings())

    # å½“WorksSpiderçˆ¬è™«å…³é—­æ—¶ï¼Œå¯åŠ¨MagnetSpider
    def on_spider_closed(spider, reason):
        if spider.name == arguments.works_spidername:  # è¿™é‡Œå‡è®¾ä½ çš„WorksSpiderçš„åå­—æ˜¯'works_spider'
            # ä¸è¦ç£åŠ›çˆ¬å–
            # process.crawl(MagnetSpider)
            pass

    dispatcher.connect(on_spider_closed, signal=signals.spider_closed)

    # å…ˆå¯åŠ¨WorksSpider
    process.crawl(WorksSpider)

    # å¼€å§‹äº‹ä»¶å¾ªç¯
    process.start()


def db_init():
    try:
        connection = pymysql.connect(**MYSQL_CONFIG)
        cursor = connection.cursor()
        mysql_op.init_db(cursor, MYSQL_DBNAME)
    except pymysql.err.OperationalError as e:
        print("ğŸ™…è¯·å…ˆé…ç½®æ•°æ®åº“ä¿¡æ¯ï¼")
        print("é…ç½®æ–‡ä»¶åœ¨: ", os.path.join(os.getcwd(), "config/database_config.py"))
        exit(-1)


def download_preview(start_date, end_date):
    pdown.download(start_date, end_date)


if __name__ == "__main__":
    # æ˜¯å¦åˆå§‹åŒ–æ•°æ®åº“
    db_init()
    main()
    # ä¸‹è½½é¢„è§ˆå›¾
    # ä½ å¯ä»¥åœ¨è¿™é‡Œå®šä¹‰æ‰€éœ€çš„æ—¥æœŸèŒƒå›´
    # start_date = "2023-08-01"
    # end_date = "2023-12-19"
    # download_preview(start_date, end_date)
    pass
